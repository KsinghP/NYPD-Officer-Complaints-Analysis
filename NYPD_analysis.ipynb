{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Many of the graphs are interactive; hover over them for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path = r'C:\\Users\\Prabhat\\Desktop\\python progs'\n",
    "    filename = \"allegations_20200726939.csv\"\n",
    "    \n",
    "    allegations_df = read_data(path, filename)\n",
    "    eda_one(allegations_df)\n",
    "    total_rows = eda_two(allegations_df)\n",
    "    allegations_df_rank = numeric_rank(allegations_df)\n",
    "    allegations_df_rank_board = numeric_board_disposition(allegations_df_rank)\n",
    "    allegations_df_ethnicity = ethnicity_calculations(allegations_df)\n",
    "    allegations_df_gender = gender_calculations(allegations_df)\n",
    "    combine_pie_charts(allegations_df_ethnicity, allegations_df_gender)\n",
    "\n",
    "    top_100_df, complaints_by_officer_df = complaints_by_officer(allegations_df_rank_board, total_rows)\n",
    "    top_100_colour_df = apply_colour(top_100_df)\n",
    "    create_bubble_chart(top_100_colour_df)    \n",
    "    allegations_df_rank_time = calculate_time_for_decision(allegations_df_rank)\n",
    "    race_of_officer = 'White' # choose from: White, Black, Asian, Hispanic, American Indian\n",
    "    create_time_histogram(allegations_df_rank_time, race_of_officer)\n",
    "    create_age_histogram(allegations_df)\n",
    "    year_received_scatterplot = 2003 # choose any value between 1985 and 2020\n",
    "    rank = 'Police Officer' # choose from: Police Officer,Detective,Sergeant,Lieutenant,Captain,\n",
    "                            # Deputy Inspector, Inspector, Chiefs and other ranks\n",
    "    year_received_sankey = 2005 # choose any value between 1985 and 2020\n",
    "    rank_vs_guilt_df = rank_vs_guilt(allegations_df_rank_time, complaints_by_officer_df, year_received_scatterplot, rank)\n",
    "    visualize_rank_changes(rank_vs_guilt_df, year_received_sankey)\n",
    "    reason = 'Stop/Question/Frisk' # the next cell has a list of reasons to choose from\n",
    "    offences_by_race(allegations_df, reason)\n",
    "    \n",
    "    allegation1 = 'Chokehold' # the next cell has a list of allegations to choose from; \n",
    "                              # you could choose only one allegation by modifying the code to drop allegation 2\n",
    "    allegation2 = 'Restricted Breathing'\n",
    "    allegation_by_ethnicity(allegations_df, allegation1, allegation2)\n",
    "    board_decision_race(allegations_df_rank_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### list of reasons: \n",
    "        'Report-domestic dispute', 'Moving violation',\n",
    "       'PD suspected C/V of violation/crime - street', 'Report-dispute',\n",
    "       'C/V telephoned PCT', 'Other', 'Regulatory inspection',\n",
    "       'Other violation of VTL', 'Parking violation',\n",
    "       'Execution of search warrant',\n",
    "       'PD suspected C/V of violation/crime - bldg', nan,\n",
    "       'Execution of arrest/bench warrant',\n",
    "       'PD suspected C/V of violation/crime - auto',\n",
    "       'Report-possession/sale of narcotics', 'Report-noise/disturbance',\n",
    "       'C/V intervened on behalf of/observed encounter w/3rd party',\n",
    "       'Traffic accident', 'Aided case', 'EDP aided case',\n",
    "       'C/V at PCT to file complaint of crime', 'Report of other crime',\n",
    "       'PD auto checkpoint', 'Demonstration/protest',\n",
    "       'Arrest/Complainant', 'C/V requested investigation of crime',\n",
    "       'Assist ACS or other agency', 'C/V at PCT to obtain information',\n",
    "       'CV already in custody', 'Report-gun possession/shots fired',\n",
    "       'Traffic Incidents/Accident/Prk Violation', 'Stop/Question/Frisk',\n",
    "       'Complainant at Pct. to make a Cmpl/info',\n",
    "       'Vehicle Stop and Check', 'C/V requested info from officer',\n",
    "       'PD suspected C/V of violation/crime - subway',\n",
    "       'Telephone Call to Precinct/Command', 'Patrol Encounter', 'Others',\n",
    "       'Arrest/Not Complainant', 'Dispute',\n",
    "       'Report of Crime Past/Present', 'Summons/Complainant',\n",
    "       'Complainant Witnessing Incident',\n",
    "       'C/V at PCT to retrieve property',\n",
    "       'Report of Disturbance/Noise Complaint', 'Parade/special event',\n",
    "       'PD telephones CV', 'EDP Aided Cases', 'Aided Cases',\n",
    "       'Demonstrations', 'Transit checkpoint',\n",
    "       'Victim Subject of Sex Crime', 'No contact'\n",
    "       \n",
    "##### list of allegations: \n",
    "       'Failure to provide RTKA card', 'Action', 'Race', 'Question',\n",
    "       'Physical force', 'Refusal to process civilian complaint',\n",
    "       'Sexual orientation', 'Word', 'Refusal to provide shield number',\n",
    "       'Retaliatory summons', 'Refusal to provide name/shield number',\n",
    "       'Search (of person)', 'Pepper spray', 'Handcuffs too tight',\n",
    "       'Frisk', 'Vehicle stop', 'Vehicle search', 'Strip-searched',\n",
    "       'Threat of arrest', 'Threat of force (verbal or physical)', 'Stop',\n",
    "       'Refusal to obtain medical treatment',\n",
    "       'Hit against inanimate object', 'Frisk and/or search', 'Other',\n",
    "       'Question and/or stop', 'Premises entered and/or searched',\n",
    "       'Gun Drawn', 'Nonlethal restraining device', 'Retaliatory arrest',\n",
    "       'Seizure of property', 'Chokehold', 'Gender',\n",
    "       'Nightstick as club (incl asp & baton)', 'Refusal to provide name',\n",
    "       'Gun Pointed', 'Threat to notify ACS',\n",
    "       'Other blunt instrument as a club', 'Property damaged',\n",
    "       'Interference with recording', 'Refusal to show search warrant',\n",
    "       'Threat to damage/seize property', 'Gesture',\n",
    "       'Sex Miscon (Sexual Harassment, Verbal)',\n",
    "       'Sex Miscon (Sexual Harassment, Gesture)',\n",
    "       'Forcible Removal to Hospital', 'Entry of Premises', 'Ethnicity',\n",
    "       'Threat of summons', 'Other - Force', 'Search of Premises',\n",
    "       'Threat re: removal to hospital', 'Vehicle',\n",
    "       'Photography/Videography', 'Demeanor/tone', 'Curse',\n",
    "       'Dragged/Pulled', 'Push/Shove', 'Detention', 'Other- Discourtesy',\n",
    "       'Mace', 'Restricted Breathing', 'Body Cavity Searches',\n",
    "       'Flashlight as club', 'Electronic device information deletion',\n",
    "       'Search of recording device', 'Gun as club', 'Nasty Words',\n",
    "       'Radio As Club', 'Threat of force', 'Nightstick/Billy/Club',\n",
    "       'Black', 'Property Damaged', 'Other - Abuse', 'Property Seized',\n",
    "       'Threat to Property', 'Religion', 'Hispanic',\n",
    "       'Sexual Misconduct (Sexual Humiliation)', 'Punch/Kick',\n",
    "       'Threat of Arrest', 'Beat', 'Gun fired', 'Other - Ethnic Slur',\n",
    "       'Flashlight As Club', 'Sex Miscon (Sexual/Romantic Proposition)',\n",
    "       'Gun pointed/gun drawn', 'Radio as club',\n",
    "       'Improper dissemination of medical info', nan, 'Person Searched',\n",
    "       'Physical disability', 'Arrest/Onlooker',\n",
    "       'Failed to Obtain Language Interpretation', 'Rude Gesture',\n",
    "       'Jewish', 'Vehicle Searched', 'Gay/Lesbian Slur',\n",
    "       'Premise Searched', 'Arrest/D. A. T.', 'Oriental', 'Sh Refuse Cmp',\n",
    "       'Slap', 'Gun As Club', 'Police shield', 'Threat of Summons',\n",
    "       'White', 'Gun pointed', 'Profane Gesture',\n",
    "       'Refusal to show arrest warrant', 'Sexist Remark', 'Other Asian',\n",
    "       'Animal', 'Gun Fired', 'Questioned immigration status',\n",
    "       'Gender Identity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "from termcolor import colored\n",
    "from simple_colors import *\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"3993\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"3993\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"3993\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '3993' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"3993\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"3993\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"3993\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '3993' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.0.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"3993\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_file, output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "output_notebook()\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "import bokeh\n",
    "from ipywidgets import interact, interact_manual\n",
    "from bokeh.models import Legend, LegendItem\n",
    "from numpy import pi\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.palettes import Spectral\n",
    "from bokeh.palettes import RdBu3\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.models import CategoricalColorMapper, HoverTool, ColumnDataSource\n",
    "from bokeh.models import FactorRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, filename):\n",
    "    allegations_df = pd.read_csv(path + \"\\\\\" + filename)\n",
    "    \n",
    "    return allegations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_one(allegations_df):\n",
    "    '''\n",
    "    preliminary EDA\n",
    "    '''\n",
    "    print (\"The data types of columns are \\n\")\n",
    "    print(allegations_df.dtypes)\n",
    "    \n",
    "    print(\"\\n A look at the first 4 rows of the data\\n\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(allegations_df.head(4))\n",
    "    \n",
    "    # columns to drop\n",
    "    allegations_df = allegations_df.drop(['command_now', 'command_at_incident', \n",
    "                                          'rank_abbrev_incident', 'rank_abbrev_now', 'precinct', 'command_now'], axis = 1)\n",
    "    # A total of 33358 complaints have been registered\n",
    "    allegations_df.shape\n",
    "    \n",
    "    # the oldest complaint dates back to 1985, and the latest to 2020\n",
    "    # the oldest complainant is 101 years old\n",
    "    # there are some negative age values for complainants, which will be dealt with at an appropriate stage\n",
    "    # the oldest officer to face a complaint is 60 years old, and the youngest 20\n",
    "    allegations_df.describe()\n",
    "    \n",
    "    # check for NA\n",
    "    allegations_df.isna().sum()\n",
    "    \n",
    "    \n",
    "    print(blue(\"\\nThere are {} unique officers in the data set\\n\\n\", ['bold']).format(allegations_df['unique_mos_id'].nunique()))\n",
    "    print (\"On average, each officer faces over 8 complaints\\n\\n\")\n",
    "    print (green(\"There are {} unique complaints in the data set\\n\\n\", ['bold']).format(allegations_df['complaint_id'].nunique()))\n",
    "    print (\"On average, each complaint mentions nearly 3 separate offences (these offences could involve the same or different \\\n",
    "           officers)\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_two(allegations_df):\n",
    "    '''\n",
    "    slightly more advanced EDA\n",
    "    '''\n",
    "\n",
    "    total_rows = allegations_df.shape[0]\n",
    "    print(yellow(\"{}% of complaints are against White officers, {}% against Hispanic & {}% against Black officers (chart below)\\n\", \\\n",
    "                 ['bold']).format(int(100*(allegations_df[allegations_df['mos_ethnicity'] == 'White'].shape[0])/total_rows), \\\n",
    "      int(100*(allegations_df[allegations_df['mos_ethnicity'] == 'Hispanic'].shape[0])/total_rows), \\\n",
    "      int(100*(allegations_df[allegations_df['mos_ethnicity'] == 'Black'].shape[0])/total_rows)))\n",
    "\n",
    "    ax1 = allegations_df['mos_ethnicity'].value_counts().plot(kind='bar')\n",
    "    ax1.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    total_rows_wo_na = allegations_df[allegations_df['complainant_ethnicity'].notna()].shape[0]\n",
    "    print(blue(\"Dropping NA values, {}% of complaints are by Black people, {}% by Hispanic & {}% by White people (chart below)\\n\", \\\n",
    "               ['bold']).format(int(100*(allegations_df[allegations_df['complainant_ethnicity'] == 'Black'].shape[0])/total_rows_wo_na),\\\n",
    "      int(100*(allegations_df[allegations_df['complainant_ethnicity'] == 'Hispanic'].shape[0])/total_rows_wo_na), \n",
    "      int(100*(allegations_df[allegations_df['complainant_ethnicity'] == 'White'].shape[0])/total_rows_wo_na)))\n",
    "\n",
    "    ax2 = allegations_df['complainant_ethnicity'].value_counts().plot(kind='bar', color = 'green')\n",
    "    ax2.grid(False)\n",
    "    plt.show()    \n",
    "    print (green(\"No arrest is made by the officer in {}% of cases (chart below) \\n\", ['bold']).\n",
    "           format(int(100*(allegations_df[allegations_df['outcome_description'] == 'No arrest made or summons issued'].\n",
    "                           shape[0])/allegations_df.shape[0])))\n",
    "    \n",
    "    ax3 = allegations_df['outcome_description'].value_counts().plot(kind='bar')\n",
    "    ax3.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    # About 2/3 complaints were made against officers with the rank Police Officer, 18% against Sergeants\n",
    "    by_off_rank_df = allegations_df.groupby('rank_incident').size().reset_index(name = 'number_of_complaints')\n",
    "\n",
    "    ax4 = plt.subplot(121, aspect='equal')\n",
    "    ax4.pie(by_off_rank_df['number_of_complaints'], autopct='%.0f%%',  startangle=10)\n",
    "    ax4.axis('equal')\n",
    "    plt.legend(labels = by_off_rank_df['rank_incident'], loc=\"best\")\n",
    "    plt.tight_layout()    \n",
    "    plt.title(\"Share of complaints by officer rank\", bbox={'facecolor':'0.8', 'pad':2})\n",
    "    ax4 = plt.gcf()\n",
    "    ax4.set_size_inches(7,7)\n",
    "    plt.show()\n",
    "    \n",
    "    # FADO: Force, Abuse of Authority, Discourtesy, Offensive Language\n",
    "    # 23% complaints involved alleged use of force by officers\n",
    "\n",
    "    by_fado_df = allegations_df.groupby('fado_type').size().reset_index(name = 'number_of_complaints')\n",
    "\n",
    "    ax5 = plt.subplot(121, aspect='equal')\n",
    "    ax5.pie(by_fado_df['number_of_complaints'], autopct='%.0f%%',  startangle=10)\n",
    "    ax5.axis('equal')\n",
    "    plt.legend(labels = by_fado_df['fado_type'], loc=\"best\")\n",
    "    plt.tight_layout()    \n",
    "    plt.title(\"Share of complaints by type\", bbox={'facecolor':'0.8', 'pad':2})\n",
    "    ax5 = plt.gcf()\n",
    "    ax5.set_size_inches(7,7) \n",
    "    plt.show()\n",
    "    \n",
    "    print(yellow(\"The board either exonerates or fails to substantiate complaint in {}% of cases (chart below) \\n\", ['bold']).\n",
    "      format(int(100*(allegations_df[(allegations_df['board_disposition'] == 'Unsubstantiated') | \n",
    "                              (allegations_df['board_disposition'] == 'Exonerated')].shape[0])/allegations_df.shape[0])))\n",
    "    \n",
    "    by_verdict_df = allegations_df.groupby('board_disposition').size().reset_index(name = 'number_of_complaints') \\\n",
    "    .sort_values('number_of_complaints', ascending = False)\n",
    "    labels = list(by_verdict_df['board_disposition'].unique())\n",
    "    ax6 = sns.barplot(x = 'board_disposition', y = 'number_of_complaints', data = by_verdict_df)\n",
    "    ax6.set_xticklabels(rotation=90, labels = labels)\n",
    "    ax6.grid(False) \n",
    "    plt.show()\n",
    "    print (\"\\n\\n\\n\")\n",
    "    return total_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. How about White cops-Black people?\n",
    "####                        &\n",
    "###         Male cops - Women?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This part tries to answer the above two questions through an interactive pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethnicity_calculations(allegations_df):\n",
    "    '''\n",
    "    calculates distribution of complaints by complainants' race, for officers from different races\n",
    "    '''\n",
    "    \n",
    "    # comp_ethnicity_df contains share of complaints by race of complainant for all officers (NaN values dropped)\n",
    "    comp_ethnicity_df = allegations_df[allegations_df['complainant_ethnicity'].notna()].groupby('complainant_ethnicity').size() \\\n",
    "    .reset_index(name='total_complaints').sort_values('total_complaints', ascending = False)\n",
    "    \n",
    "    comp_ethnicity_df['percentage_of_overall_complaints'] = round(comp_ethnicity_df['total_complaints']*100/allegations_df \\\n",
    "                                                                  [allegations_df['complainant_ethnicity'].notna()].shape[0],1)\n",
    "    \n",
    "    # off_ethnicity_df contains share of complaints by race of officer\n",
    "    off_ethnicity_df = allegations_df[allegations_df['complainant_ethnicity'].notna()].groupby('mos_ethnicity').size() \\\n",
    "    .reset_index(name='number_of_complaints').sort_values('number_of_complaints', ascending = False)\n",
    "    \n",
    "    off_ethnicity_df['percentage_of_complaints'] = round(off_ethnicity_df['number_of_complaints']*100/allegations_df \\\n",
    "                                                         [allegations_df['complainant_ethnicity'].notna()].shape[0],1)\n",
    "    \n",
    "    # off_comp_ethnicity_df contains number of complaints by race of complainant, for each different race of officer\n",
    "    off_comp_ethnicity_df = allegations_df.groupby(['complainant_ethnicity', 'mos_ethnicity']).size().reset_index \\\n",
    "    (name='number_of_complaints')\n",
    "\n",
    "    # merge the above two dataframes to calculate share of complaints by race of complainant, for officers of each different race\n",
    "    merge_race_df = comp_ethnicity_df.merge(off_comp_ethnicity_df,on='complainant_ethnicity').merge(off_ethnicity_df,on='mos_ethnicity')\n",
    "    \n",
    "    merge_race_df['percentage_of_complaints'] = round(merge_race_df['number_of_complaints_x']*100/merge_race_df['number_of_complaints_y'],1)\n",
    "    \n",
    "    # retaining only the relevant columns\n",
    "    merge_race_df = merge_race_df[['mos_ethnicity', 'complainant_ethnicity', 'percentage_of_complaints', 'percentage_of_overall_complaints']]\n",
    "    \n",
    "    return merge_race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_calculations(allegations_df):\n",
    "    '''\n",
    "    calculates distribution of complaints by complainants' gender, for officers from different genders\n",
    "    based on a logic similar to the above function ethnicity_calculations\n",
    "    '''\n",
    "    \n",
    "    comp_gender_df = allegations_df[allegations_df['complainant_gender'].notna()].groupby('complainant_gender').size().reset_index \\\n",
    "    (name='total_complaints').sort_values('total_complaints', ascending = False)\n",
    "    \n",
    "    comp_gender_df['percentage_of_overall_complaints'] = round(comp_gender_df['total_complaints']*100/allegations_df[allegations_df \\\n",
    "                                                               ['complainant_gender'].notna()].shape[0],1)\n",
    "    \n",
    "    off_comp_gender_df = allegations_df.groupby(['complainant_gender', 'mos_gender']).size().reset_index(name='number_of_complaints')\n",
    "    \n",
    "    off_gender_df = allegations_df[allegations_df['complainant_gender'].notna()].groupby('mos_gender').size().reset_index \\\n",
    "    (name='number_of_complaints').sort_values('number_of_complaints', ascending = False)\n",
    "    \n",
    "    off_gender_df['percentage_of_complaints'] = round(off_gender_df['number_of_complaints']*100/allegations_df.shape[0],1)\n",
    "    \n",
    "    merge_gender_df = comp_gender_df.merge(off_comp_gender_df,on='complainant_gender').merge(off_gender_df,on='mos_gender')\n",
    "    \n",
    "    merge_gender_df['percentage_of_complaints'] = round(merge_gender_df['number_of_complaints_x']*100/merge_gender_df \\\n",
    "                                                                                         ['number_of_complaints_y'],1)\n",
    "    # retaining only the relevant columns\n",
    "    merge_gender_df = merge_gender_df[['mos_gender', 'complainant_gender', 'percentage_of_complaints', 'percentage_of_overall_complaints']]\n",
    "    \n",
    "    return merge_gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_pie_chart(race_of_accused, race_pie_chart_df):\n",
    "    '''\n",
    "    creates pie chart for racial distribution of complaints\n",
    "    '''\n",
    "    \n",
    "    df_race = race_pie_chart_df.loc[race_pie_chart_df['mos_ethnicity'] == race_of_accused]\n",
    "    \n",
    "    df_race['angle'] = (df_race['percentage_of_complaints']*2*pi)/100\n",
    "    \n",
    "    df_race['color'] = Category20c[len(df_race)]    \n",
    "    \n",
    "    plot_race = figure(plot_height=350, \n",
    "                       title= \"Race-wise proportion of victims when officer is {}\".format(race_of_accused), \n",
    "                       toolbar_location=None, \n",
    "                       tools=\"hover\", \n",
    "                       tooltips = \"@complainant_ethnicity:@percentage_of_complaints\")\n",
    "    \n",
    "    plot_race.wedge(x=0, y=1, radius=0.3, \n",
    "                    start_angle=cumsum('angle', include_zero=True), \n",
    "                    end_angle=cumsum('angle'), \n",
    "                    line_color=\"white\", \n",
    "                    fill_color='color', \n",
    "                    source=df_race)    \n",
    "    \n",
    "    return plot_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_pie_chart(gender_of_accused, gender_pie_chart_df):\n",
    "    '''\n",
    "    creates pie chart for gender-wise distribution of complaints\n",
    "    '''\n",
    "    c1 = RdBu3[2] # red\n",
    "    c2 = RdBu3[0] # blue\n",
    "\n",
    "    df_gender = gender_pie_chart_df.loc[gender_pie_chart_df['mos_gender'] == gender_of_accused]\n",
    "    \n",
    "    df_gender['angle'] = (df_gender['percentage_of_complaints']*2*pi)/100\n",
    "    \n",
    "    df_gender['color'] = Category20c[len(df_gender)]\n",
    "    \n",
    "    plot_gender = figure(plot_height=350, \n",
    "                         title= \"Gender-wise proportion of victims when officer is {}\".format(gender_of_accused), \n",
    "                         toolbar_location=None, \n",
    "                         tools=\"hover\", \n",
    "                         tooltips = \"@complainant_gender:@percentage_of_complaints\")\n",
    "    \n",
    "    plot_gender.wedge(x=0, y=1, radius=0.4, start_angle=cumsum('angle', include_zero=True), \n",
    "                      end_angle=cumsum('angle'), \n",
    "                      line_color=\"white\", \n",
    "                      fill_color='color',\n",
    "                      source=df_gender)\n",
    "    \n",
    "    return plot_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pie_charts(merge_race_df, merge_gender_df):\n",
    "    '''\n",
    "    combines race and gender pie charts into a single Bokeh plot\n",
    "    '''\n",
    "    \n",
    "    races = list(merge_race_df.reset_index()['mos_ethnicity'].unique())\n",
    "    genders = list(merge_gender_df.reset_index()['mos_gender'].unique())\n",
    "\n",
    "    race_plots = [race_pie_chart(race, merge_race_df) for race in races]\n",
    "    race_plots\n",
    "    race_gridplot = gridplot([[race_plots[0], race_plots[1]],\n",
    "                              [race_plots[2], race_plots[3]],\n",
    "                              [race_plots[4], None]])\n",
    "    race_panel = Panel(child = race_gridplot, title = 'Race-wise breakup of complaints')\n",
    "\n",
    "    gender_plots = [gender_pie_chart(gender,merge_gender_df) for gender in genders]\n",
    "    \n",
    "    gender_gridplot = gridplot([[gender_plots[0], gender_plots[1], None]])\n",
    "    \n",
    "    gender_panel = Panel(child = gender_gridplot, title = 'Gender-wise breakup of complaints')\n",
    "\n",
    "    tabs = Tabs(tabs=[race_panel, gender_panel])\n",
    "    show(tabs)\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Who are the most errant officers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This part explores the 100 officers with most complaints against them\n",
    "##### For each officer, parameters explored: total complaints, ethnicity, rank, no. of complaints in which found guilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complaints_by_officer(allegations_df, total_rows):\n",
    "    '''\n",
    "    creates a dataframe, top_100_df, containing only the top 100 officers with most complaints\n",
    "    '''\n",
    "    # group by each unique officer to find his/her average guilty score, calculated with the help of the column numeric_board_finding\n",
    "    # numeric_board_finding = 0 for Unsubstantiated or Exonerated, and 1 for Substantiated\n",
    "    complaints_by_officer_df = allegations_df.groupby('unique_mos_id').agg({'unique_mos_id':'size', 'numeric_board_finding':'mean'}) \\\n",
    "    .rename(columns={'unique_mos_id':'number_of_complaints', 'numeric_board_finding':'avg_guilty_score'}).reset_index().sort_values \\\n",
    "    ('number_of_complaints', ascending=False)\n",
    "    \n",
    "    # create a new column, total_guilty_finding, to find the no. of complaints in which an officer has been found guilty\n",
    "    complaints_by_officer_df['total_guilty_finding'] = round(complaints_by_officer_df['number_of_complaints']*complaints_by_officer_df \\\n",
    "                                                             ['avg_guilty_score'], 0)\n",
    "    \n",
    "    # arrange by no. of complaints and drop duplicate IDs to reduce dataframe to the 3996 unique officers\n",
    "    merge_complaints_df = pd.merge(complaints_by_officer_df, allegations_df, on = 'unique_mos_id')\n",
    "    \n",
    "    merge_complaints_df_sorted = merge_complaints_df.sort_values('number_of_complaints', ascending = False) \n",
    "    \n",
    "    merge_complaints_df_sorted.drop_duplicates(keep='first',inplace=True, subset =\"unique_mos_id\")\n",
    "    \n",
    "    # the final dataframe\n",
    "    top_100_df = merge_complaints_df_sorted.head(100)\n",
    "    \n",
    "    print(green(\"The 100 most errant officers - 2.5% of total - are responsible for {}% of total complaints (chart below) \\n\", ['bold']).\n",
    "          format(int(100*(top_100_df['number_of_complaints'].sum())/total_rows)))\n",
    "       \n",
    "    return top_100_df, complaints_by_officer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_colour(top_100_df):\n",
    "    '''\n",
    "    colour chart bubbles differently as per no. of complaints\n",
    "    '''\n",
    "    top_100_df.loc[top_100_df['number_of_complaints'] < 40, 'colour'] = 'green'\n",
    "    \n",
    "    top_100_df.loc[((top_100_df['number_of_complaints'] >= 40) & (top_100_df['number_of_complaints'] < 60)), 'colour'] = 'orange'\n",
    "    \n",
    "    top_100_df.loc[top_100_df['number_of_complaints'] >= 60, 'colour'] = 'red'\n",
    "    \n",
    "    return top_100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bubble_chart(top_100_colour_df):\n",
    "    cds = ColumnDataSource(top_100_colour_df)\n",
    "    \n",
    "    p_id = figure(plot_height = 650, plot_width = 1000, \n",
    "           title = 'The 100 officers with most complaints', x_axis_label = '',  y_axis_label = 'Number of Complaints')\n",
    "\n",
    "    p_id.circle(x='unique_mos_id', y='number_of_complaints',\n",
    "         source=cds,\n",
    "         size=10, color='colour')\n",
    "\n",
    "    hover = HoverTool(tooltips = [('First Name', '@first_name'),\n",
    "                             ('Last Name', '@last_name'), ('Current Rank', '@rank_now'), \n",
    "                              ('Ethnicity', '@mos_ethnicity'), ('Complaints', '@number_of_complaints'),\n",
    "                             ('Found guilty in', '@total_guilty_finding')])\n",
    "\n",
    "    # Style the plot\n",
    "    p_id.xaxis.major_tick_line_color = None\n",
    "    p_id.xaxis.minor_tick_line_color = None\n",
    "    p_id.xaxis.major_label_text_font_size = '0pt'  # turn off x-axis tick labels\n",
    "    p_id.xgrid.grid_line_color = None\n",
    "    p_id.ygrid.grid_line_color = None\n",
    "    p_id.yaxis.axis_label_text_font_style = 'bold'\n",
    "    p_id.title.align = 'center'\n",
    "    p_id.title.text_font_size = '15pt'\n",
    "    p_id.title.text_font = 'serif'\n",
    "\n",
    "    # Add the hover tool to the graph\n",
    "    p_id.add_tools(hover)\n",
    "\n",
    "    show(p_id)\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Does an officer's ethnicity decide how quickly (or slowly) the board reaches a decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An interactive histogram tells us that this isn't the case (hover over for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_for_decision(allegations_df):\n",
    "    '''\n",
    "    creates a new column, months_to_close, to calculate the time taken by the board to reach a decision\n",
    "    '''\n",
    "    \n",
    "    allegations_df['combine_r_year_month'] = allegations_df['year_received'].astype(str) + \"-\" + allegations_df['month_received'].\\\n",
    "                                                                                                                      astype(str)\n",
    "    \n",
    "    allegations_df['combine_c_year_month'] = allegations_df['year_closed'].astype(str) + \"-\" + allegations_df['month_closed'].\\\n",
    "                                                                                                                   astype(str)\n",
    "\n",
    "    allegations_df['received_year_month'] = pd.to_datetime(allegations_df['combine_r_year_month'].astype(str), format='%Y-%m')\n",
    "    \n",
    "    allegations_df['closed_year_month'] = pd.to_datetime(allegations_df['combine_c_year_month'].astype(str), format='%Y-%m')\n",
    "\n",
    "    allegations_df['months_to_close'] = round(((allegations_df['closed_year_month'] - allegations_df['received_year_month'])/ \\\n",
    "                                               np.timedelta64(1, 'M')),0)\n",
    "    \n",
    "    return allegations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_histogram(allegations_df, race_of_officer):\n",
    "    '''\n",
    "    creates a histogram for distribution of complaints by time taken (in months) to reach a decision\n",
    "    drawing the histogram exclusively for officers of White and Black ethnicities produces similar results\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    arr_hist, edges = np.histogram(allegations_df[allegations_df['mos_ethnicity'] == race_of_officer]['months_to_close'], \\\n",
    "                                   bins = 15,range = [0, 105])\n",
    "\n",
    "    time_df = pd.DataFrame({'number_of_complaints': arr_hist, \n",
    "                       'left': edges[:-1], \n",
    "                       'right': edges[1:]})\n",
    "\n",
    "    time_df['right'] = time_df['right'] - 1\n",
    "    \n",
    "    time_df['time_interval'] = ['%d to %d months' % (left, right) for left, right in zip(time_df['left'], (time_df['right']))]\n",
    "    \n",
    "    time_df['proportion_of_complaints'] = time_df['number_of_complaints']/time_df['number_of_complaints'].sum()\n",
    "    \n",
    "    src = ColumnDataSource(time_df)\n",
    "\n",
    "    p_time = figure(plot_height = 600, plot_width = 600, \n",
    "           title = 'Distribution of time taken by Board for complaints against {} officers'.format(race_of_officer),\n",
    "          x_axis_label = 'Months taken to reach decision', \n",
    "           y_axis_label = 'Number of Complaints')\n",
    "\n",
    "    p_time.quad(source = src, bottom=0, top='number_of_complaints', left='left', right='right', \n",
    "       fill_color='red', line_color='black')\n",
    "\n",
    "    hover = HoverTool(tooltips = [('Time Bracket (months)', '@time_interval'),\n",
    "                             ('Proportion of complaints solved', '@proportion_of_complaints')])\n",
    "\n",
    "    p_time.title.align = 'center'\n",
    "    p_time.add_tools(hover)\n",
    "    \n",
    "    show(p_time)\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Are the youth more likely to face police abuse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The interactive histogram generated by this part confirms this intuition (hover over for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_age_histogram(allegations_df):\n",
    "    '''\n",
    "    creates a histogram for distribution of complaints by ages of complainants\n",
    "    '''\n",
    "    arr_hist, edges = np.histogram(allegations_df[allegations_df['complainant_age_incident'] > 0]['complainant_age_incident'], \n",
    "                               bins = 15, \n",
    "                               range = [0, 105])\n",
    "    \n",
    "    age_df = pd.DataFrame({'number_of_complaints': arr_hist, \n",
    "                       'left': edges[:-1], \n",
    "                       'right': edges[1:]})\n",
    "    \n",
    "    age_df['right'] = age_df['right'] - 1\n",
    "    \n",
    "    age_df['age_interval'] = ['%d to %d years' % (left, right) for left, right in zip(age_df['left'], (age_df['right']))]\n",
    "    \n",
    "    age_df['proportion_of_complaint'] = age_df['number_of_complaints']/age_df['number_of_complaints'].sum()\n",
    "    \n",
    "    src = ColumnDataSource(age_df)\n",
    "    p = figure(plot_height = 600, plot_width = 600, \n",
    "           title = \"Histogram of complainants' age\",\n",
    "          x_axis_label = 'Age', \n",
    "           y_axis_label = 'Number of Complaints')\n",
    "\n",
    "    p.quad(source = src, bottom=0, top='number_of_complaints', left='left', right='right', \n",
    "       fill_color='blue', line_color='black')\n",
    "\n",
    "    hover = HoverTool(tooltips = [('Age Bracket', '@age_interval'),\n",
    "                             ('Proportion of complaint', '@proportion_of_complaint')])\n",
    "\n",
    "    p.add_tools(hover)\n",
    "    show(p)\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Does being found guilty of misconduct affect officers' promotion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A scatter plot generated by this part for each of the 3996 officers, of average guilty score vs. promotion, doesn't suggest so\n",
    "\n",
    "##### Promotion is calculated as change in rank between the current rank and the rank at the time of first complaint\n",
    "\n",
    "##### Average guilty score for an officer is the average of the number of times the board substantiates a complaint against the officer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_vs_guilt(allegations_df, complaints_by_officer_df, year_received_scatterplot, rank):\n",
    "    '''\n",
    "    creates a dataframe, rank_vs_guilt_df, which has one entry for every officer as per the date of the first complaint\n",
    "    against the officer\n",
    "    '''\n",
    "    \n",
    "    # merging to get the 'received_year_month' column\n",
    "    merge_df = pd.merge(allegations_df, complaints_by_officer_df, on = 'unique_mos_id')\n",
    "    \n",
    "    rank_vs_guilt_df = merge_df.sort_values('received_year_month', ascending = False)\n",
    "    rank_vs_guilt_df.drop_duplicates(keep='last',inplace=True, subset =\"unique_mos_id\")\n",
    "    \n",
    "    # plot change in rank against average guilty score\n",
    "    dims = (10,10)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    \n",
    "    year_ahead = year_received_scatterplot + 1\n",
    "    year_behind = year_received_scatterplot - 1\n",
    "    \n",
    "    number_of_officers = rank_vs_guilt_df[(rank_vs_guilt_df['rank_incident'] == rank) & ((rank_vs_guilt_df['year_received'] \\\n",
    "    == year_received_scatterplot)  | (rank_vs_guilt_df['year_received'] == year_ahead) | (rank_vs_guilt_df['year_received'] == \\\n",
    "                                                                                          year_behind))].shape[0]\n",
    "    \n",
    "    print(\"A total of {} officers of rank {} faced their first complaint in {}, {}, {}\\n\".format(number_of_officers, rank, \n",
    "                                                                      year_behind, year_received_scatterplot, year_ahead))\n",
    "    \n",
    "    print(green(\"The correlation between average guilty score and rank change for these officers is {} (chart below) \\n\", \\\n",
    "                ['bold']).format(round(rank_vs_guilt_df[(rank_vs_guilt_df['rank_incident'] == rank) & ((rank_vs_guilt_df \\\n",
    "                ['year_received'] == year_behind)  | (rank_vs_guilt_df['year_received'] == year_received_scatterplot) | \\\n",
    "                (rank_vs_guilt_df['year_received'] == year_ahead))]['avg_guilty_score'].corr(rank_vs_guilt_df[(rank_vs_guilt_df \\\n",
    "                ['rank_incident'] == rank) & ((rank_vs_guilt_df['year_received'] == year_behind) \\\n",
    "                | (rank_vs_guilt_df['year_received'] == year_received_scatterplot) | (rank_vs_guilt_df['year_received'] \\\n",
    "                                                                       == year_ahead))]['numeric_rank_change']),2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = sns.scatterplot(x='avg_guilty_score', y='numeric_rank_change', hue = 'rank_incident', \n",
    "                         data=rank_vs_guilt_df[(rank_vs_guilt_df['rank_incident'] == rank) & ((rank_vs_guilt_df['year_received'] \\\n",
    "                       == year_received_scatterplot)  | (rank_vs_guilt_df['year_received'] == year_ahead) | (rank_vs_guilt_df \\\n",
    "                                    ['year_received'] == year_behind))])\n",
    "    \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.1, 0.5), ncol=1, title='Rank in year of first complaint')\n",
    "    \n",
    "    ax.set(xlabel='Average guilty score of each officer', ylabel='Rank change b/w year of first complaint and now')\n",
    "    \n",
    "    ax.set_title(\"Promotion vs avg guilt score for officers of rank {} who faced their first complaint in {}, {}, {}\".format \\\n",
    "                 (rank, year_behind, year_received_scatterplot, year_ahead))\n",
    "    \n",
    "    plt.savefig('Scatterplot of promotion vs average guilt score.png')\n",
    "    plt.show()\n",
    "    print (\"\\n\\n\\n\")\n",
    "    \n",
    "    return rank_vs_guilt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7. Visualize changes in ranks of each of the 3996 officers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the initial rank, an officer's rank at the time of the first complaint is chosen\n",
    "##### Due to this methodology, only the change in rank b/w the time of the first complaint and the current time is visible\n",
    "##### Diagram generated by this part renders outside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rank_changes(rank_vs_guilt_df, year_received_sankey):\n",
    "    '''\n",
    "    visualizes changes in ranks of each of the 3996 officers through a sankey diagram rank_vs_guilt_df\n",
    "    is taken from the function rank_vs_guilt, which is written right below this function\n",
    "    '''\n",
    "    # diagram is made for all officers that faced their first complaint in year_received_sankey, and one year before and after that \n",
    "    year_ahead = year_received_sankey + 1\n",
    "    year_behind = year_received_sankey - 1\n",
    "    \n",
    "    weighted_mean = lambda x: np.average(x, weights=rank_vs_guilt_df.loc[x.index, \"number_of_complaints\"])\n",
    "    \n",
    "    dictionary = {'unique_mos_id':'size', 'avg_guilty_score': weighted_mean}\n",
    "    # sankey_df produces numbers on changes between every pair of ranks, which are entered in links (below) to make the diagram \n",
    "    sankey_df = rank_vs_guilt_df[(rank_vs_guilt_df['year_received'] == year_received_sankey) | (rank_vs_guilt_df['year_received'] \\\n",
    "               == year_ahead) | (rank_vs_guilt_df['year_received'] == year_behind)].groupby(['rank_incident', 'rank_now'],\\\n",
    "               as_index=False).agg(dictionary).rename(columns = {'unique_mos_id':'number_of_officers', 'avg_guilty_score': \\\n",
    "                                                                                               'weighted_average_guilt'})\n",
    "    \n",
    "    # assign numerals to current rank and rank at the time of the first complaint for every officer \n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Police Officer', 'numeric_rank_incident'] = 0\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Detective', 'numeric_rank_incident'] = 1\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Sergeant', 'numeric_rank_incident'] = 2\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Lieutenant', 'numeric_rank_incident'] = 3\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Captain', 'numeric_rank_incident'] = 4\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Deputy Inspector', 'numeric_rank_incident'] = 5\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Inspector', 'numeric_rank_incident'] = 6\n",
    "    sankey_df.loc[sankey_df['rank_incident'] == 'Chiefs and other ranks', 'numeric_rank_incident'] = 7\n",
    "    \n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Police Officer', 'numeric_rank_now'] = 8\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Detective', 'numeric_rank_now'] = 9\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Sergeant', 'numeric_rank_now'] = 10\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Lieutenant', 'numeric_rank_now'] = 11\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Captain', 'numeric_rank_now'] = 12\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Deputy Inspector', 'numeric_rank_now'] = 13\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Inspector', 'numeric_rank_now'] = 14\n",
    "    sankey_df.loc[sankey_df['rank_now'] == 'Chiefs and other ranks', 'numeric_rank_now'] = 15\n",
    "\n",
    "    # links and nodes are created for the sankey diagram\n",
    "    links = [[]]\n",
    "    index = 0\n",
    "    number_of_colours = len(sankey_df)\n",
    "    colours = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colours)]\n",
    "\n",
    "    for rank_i, rank_n, value, avg in zip(sankey_df['numeric_rank_incident'].values, \n",
    "                                     sankey_df['numeric_rank_now'].values, \n",
    "                                     sankey_df['number_of_officers'].values, sankey_df['weighted_average_guilt'].values):\n",
    "        colour = colours[index]\n",
    "        rank_list = [rank_i, rank_n, value, round(avg,2), colour]\n",
    "        links.insert(index, rank_list)\n",
    "        index = index + 1\n",
    "    \n",
    "    nodes = [[0,'Police Officer','#4994CE'],\n",
    "        [1,'Detective','#8A5988'],\n",
    "        [2,'Sergeant','#A0522D'],\n",
    "        [3,'Lieutenant','#ffe873'],\n",
    "        [4,'Captain','#646464'],\n",
    "        [5,'Deputy Inspector','#449E9E'],\n",
    "        [6,'Inspector',' #306998'],\n",
    "        [7,'Chiefs and other ranks','#ffd43b'],\n",
    "        [8,'Police Officer','#4994CE'],\n",
    "        [9,'Detective','#8A5988'],\n",
    "        [10,'Sergeant','#A0522D'],\n",
    "        [11,'Lieutenant','#ffe873'],\n",
    "        [12,'Captain','#646464'],\n",
    "        [13,'Deputy Inspector','#449E9E'],\n",
    "        [14,'Inspector',' #306998'],\n",
    "        [15,'Chiefs and other ranks','#ffd43b'],]\n",
    "    \n",
    "    df_nodes = pd.DataFrame(nodes, columns = ['ID', 'Label', 'Colour'])\n",
    "    df_links = pd.DataFrame(links, columns = ['Source', 'Target', 'Value', 'Avg Score', 'Link Colour'])\n",
    "\n",
    "    data_trace = dict(\n",
    "    type='sankey',\n",
    "    domain = dict(\n",
    "      x =  [0,1],\n",
    "      y =  [0,1]\n",
    "    ),\n",
    "    orientation = \"h\",\n",
    "    valueformat = \".0f\",\n",
    "    node = dict(\n",
    "      pad = 10,\n",
    "    # thickness = 30,\n",
    "      line = dict(\n",
    "        color = \"black\",\n",
    "        width = 0\n",
    "      ),\n",
    "      label =  df_nodes['Label'].dropna(axis=0, how='any'),\n",
    "      color = df_nodes['Colour']\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = df_links['Source'].dropna(axis=0, how='any'),\n",
    "      target = df_links['Target'].dropna(axis=0, how='any'),\n",
    "      value = df_links['Value'].dropna(axis=0, how='any'),\n",
    "      color = df_links['Link Colour'].dropna(axis=0, how='any'),\n",
    "      label= df_links['Avg Score'].dropna(axis=0, how='any'),\n",
    "    )\n",
    "    )\n",
    "\n",
    "    layout = dict(\n",
    "        title = \"Change in ranks and average guilty scores of officers who faced their first complaint in the years {}, {}, {}\".format(year_behind, year_received_sankey, year_ahead),\n",
    "    height = 772,\n",
    "    font = dict(\n",
    "      size = 10),)\n",
    "    \n",
    "    fig = dict(data=[data_trace], layout=layout)\n",
    "    plotly.offline.plot(fig, validate=False, image = 'png', image_filename='Change in ranks', output_type='file', image_width=1000,\\\n",
    "                        image_height=720, filename='temp-plot.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8: Are Black people singled out for certain offences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contrary to intuition, Black people don't have a particularly high share of complaints for offences such as parking violation\n",
    "##### For Stop/Question/Frisk, 100% of complaints come from Black people, but this is from a sample of just 4 (the rest 202 are NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offences_by_race(allegations_df, reason):\n",
    "    '''\n",
    "    plots a pie chart to show distribution of chosen offence (contact_reason) by race of complainants\n",
    "    '''\n",
    "    contact_by_ethnicity_df = allegations_df[(allegations_df['contact_reason'] == reason)].groupby('complainant_ethnicity').size() \\\n",
    "    .reset_index(name = 'number_of_complaints')\n",
    "    \n",
    "    ax = plt.subplot(121, aspect='equal')\n",
    "    ax.pie(contact_by_ethnicity_df['number_of_complaints'], autopct='%.0f%%',  startangle=10, labeldistance=1.2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    plt.legend(labels = contact_by_ethnicity_df['complainant_ethnicity'], loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Share of complaints by ethnicity for contact reason {}\".format(reason), bbox={'facecolor':'0.8', 'pad':6})\n",
    "    \n",
    "    ax = plt.gcf()\n",
    "    ax.set_size_inches(14,10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 9: How often have cops been accused of chokehold/restricting breathing, and by which races?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Less than 1% complaints pertain to either chokehold or restricted breathing, and 61% of those are by Black People (similar to their overall share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allegation_by_ethnicity(allegations_df, allegation1, allegation2):\n",
    "    '''\n",
    "    creates pie chart showing distribution of chokehold/restricted breathing by race\n",
    "    '''\n",
    "    \n",
    "    allegation_by_ethnicity_df = allegations_df[(allegations_df['allegation'] == allegation1) | (allegations_df['allegation'] == \\\n",
    "                              allegation1)].groupby('complainant_ethnicity').size().reset_index(name = 'number_of_complaints')\n",
    "    \n",
    "    print(blue(\"Dropping NaN, the total number of complaints against either chokehold or restricted breathing are {}\\n\", ['bold']) \\\n",
    "          .format(allegation_by_ethnicity_df['number_of_complaints'].sum()))\n",
    "    \n",
    "    ax = plt.subplot(121, aspect='equal')\n",
    "    ax.pie(allegation_by_ethnicity_df['number_of_complaints'], autopct='%.0f%%',  startangle=10, labeldistance=1.2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    plt.legend(labels = allegation_by_ethnicity_df['complainant_ethnicity'], loc=\"best\")\n",
    "    plt.tight_layout()    \n",
    "    plt.title(\"Share of chokehold/restricted breathing by ethnicity\", bbox={'facecolor':'0.8', 'pad':6})\n",
    "    \n",
    "    ax = plt.gcf()\n",
    "    ax.set_size_inches(14,10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 10: Does the board's decision depend on the race of the complainant and the officer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The results are quite striking: American Indians, officers as well as complainants, enjoy a distinct advantage over other races.\n",
    "##### The board is more likely to acquit American Indian officers, and determine guilt in complaints filed by American Indian complainants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_decision_race(allegations_df):\n",
    "    '''\n",
    "    creates and merges dataframes containing average guilty scores (as calcultated in the function numeric_board_disposition) \n",
    "    by race of officer and complainant, and plots them\n",
    "    '''\n",
    "    \n",
    "    # average guilty scores by race of officer \n",
    "    off_ethnicity_guilty_df = allegations_df.groupby('mos_ethnicity')['numeric_board_finding'].mean().reset_index(name = \\\n",
    "                                         'avg_guilty_score_off').sort_values('avg_guilty_score_off', ascending=False)\n",
    "    \n",
    "    # avrage guilty scores by race of complainant\n",
    "    com_ethnicity_guilty_df = allegations_df.groupby('complainant_ethnicity')['numeric_board_finding'].mean().reset_index(name = \\\n",
    "                                                                                                'avg_guilty_score_com')\n",
    "    \n",
    "    # merge the two to make a pie chart\n",
    "    ethnicity_guilty_merge_df = pd.merge(off_ethnicity_guilty_df, com_ethnicity_guilty_df, left_on='mos_ethnicity', right_on= \\\n",
    "                                         'complainant_ethnicity', how = 'inner')\n",
    "    \n",
    "    # plot pie chart\n",
    "    x = np.arange(5)\n",
    "    w = 0.3\n",
    "    ax1 = plt.subplot(1,1,1)\n",
    "    plt.xticks(x + w /2, ethnicity_guilty_merge_df['mos_ethnicity'], rotation='vertical')\n",
    "    plt.title(\"Proportion of complaints found guilty by race\")\n",
    "    officer = ax1.bar(x, ethnicity_guilty_merge_df['avg_guilty_score_off'], color='#4994CE', width=w, align='center')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    complainant = ax2.bar(x + w, ethnicity_guilty_merge_df['avg_guilty_score_com'], color='#A0522D', width=w, align='center')\n",
    "    plt.legend([officer, complainant], ['Officer Race', 'Complainant Race'], loc=\"best\", bbox_to_anchor=(1.1, 0.5))\n",
    "    \n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    ax2.set_yticks([10], minor = False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign numerical values to officer ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I have assigned values to ranks in ascending order as per NYPD hierarchy (https://nypd.fandom.com/wiki/NYPD_Uniforms_and_Ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### {'Police Officer': 0, 'Detective': 1, 'Sergeant': 2, 'Lieutenant': 3, 'Captain': 4, 'Deputy Inspector': 5, 'Inspector': 6, 'Chiefs and other ranks': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_rank(allegations_df):\n",
    "    '''\n",
    "    assigns numeric values to ranks at the time of complaint and at the current time, and calculates the difference\n",
    "    b/w them\n",
    "    '''\n",
    "    # new column for numeric rank at the time of complaint\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Police Officer', 'numeric_rank_incident'] = 0\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Detective', 'numeric_rank_incident'] = 1\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Sergeant', 'numeric_rank_incident'] = 2\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Lieutenant', 'numeric_rank_incident'] = 3\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Captain', 'numeric_rank_incident'] = 4\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Deputy Inspector', 'numeric_rank_incident'] = 5\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Inspector', 'numeric_rank_incident'] = 6\n",
    "    allegations_df.loc[allegations_df['rank_incident'] == 'Chiefs and other ranks', 'numeric_rank_incident'] = 7\n",
    "    \n",
    "    # new column for numeric rank at the current time\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Police Officer', 'numeric_rank_now'] = 0\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Detective', 'numeric_rank_now'] = 1\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Sergeant', 'numeric_rank_now'] = 2\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Lieutenant', 'numeric_rank_now'] = 3\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Captain', 'numeric_rank_now'] = 4\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Deputy Inspector', 'numeric_rank_now'] = 5\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Inspector', 'numeric_rank_now'] = 6\n",
    "    allegations_df.loc[allegations_df['rank_now'] == 'Chiefs and other ranks', 'numeric_rank_now'] = 7\n",
    "    \n",
    "    # new column to calculate difference in numeric ranks\n",
    "    allegations_df['numeric_rank_change'] = allegations_df['numeric_rank_now'] - allegations_df['numeric_rank_incident']\n",
    "    \n",
    "    return allegations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign numerical values to findings of the disciplinary board (board_disposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Among the board findings (board_disposition) both Unsubstantiated and Exonerated have been assigned 0 \n",
    "##### The several different forms of Substantiated findings - charges, command discipline etc. - have all been assigned 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_board_disposition(allegations_df):\n",
    "    '''\n",
    "    makes a new column, board_finding, that creates one category for Unsubstantiated and Exonerated, and another for all \n",
    "    different forms of Substantiated; numeric_board_finding assigns 0 to Unsubstantiated/Exonerated category, and 1 to Substantiated category\n",
    "    '''\n",
    "    \n",
    "    for idx, finding in enumerate(allegations_df.board_disposition.values):\n",
    "        word = re.findall(\"^(Substantiated)\", finding)\n",
    "        if word == ['Substantiated']:\n",
    "            allegations_df.loc[idx, 'board_finding'] = word\n",
    "        else:\n",
    "            allegations_df.loc[idx, 'board_finding'] = 'Unsubstantiated or exonerated'\n",
    "    \n",
    "    allegations_df.loc[allegations_df['board_finding'] == 'Unsubstantiated or exonerated', 'numeric_board_finding'] = 0\n",
    "    allegations_df.loc[allegations_df['board_finding'] == 'Substantiated', 'numeric_board_finding'] = 1\n",
    "    \n",
    "    return allegations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
